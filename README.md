# GPT2_With_LoRA

## What is LoRA?
- LoRA, or Low-Rank Adaptation, is a technique used to fine-tune large language models (LLMs) efficiently by adding small, trainable matrices to the model while keeping the original weights unchanged.
- This approach significantly reduces the number of parameters that need to be trained, making it more resource-efficient and faster compared to traditional fine-tuning methods.
